{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printer Supplies Scrapper\n",
    "\n",
    "Script that loads a csv into pandas, parse the IPs in python and request the webpage, update values and save to new csv\n",
    "\n",
    "-- Jupyter Notebook envirnment running Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "https://stackoverflow.com/questions/71025130/how-to-extract-a-table-from-a-website-using-beautifulsoup\n",
    "\n",
    "Wants: multithreading or multiprocessing to speed up requests resolution -> then short by name.\n",
    "\n",
    "Im striping the index and the adding back by index. if I just make json file to parse then I dont need to run csv.\n",
    "- I can break the functions apart and only call what I need\n",
    "- in flask app I could have the app call the function based on the json and get a return value\n",
    "\n",
    "\n",
    "```python\n",
    "JSON({\n",
    "    Name: Name, \n",
    "    {\n",
    "        Name: VALUE\n",
    "        IP: VALUE\n",
    "        # rest of the supply list\n",
    "        Black Toner: VALUE,\n",
    "        Cyan Toner: VALUE,\n",
    "        Magenta Toner: VALUE,\n",
    "        Yellow Toner: VALUE,\n",
    "        Drum Cartridge (R1): VALUE,\n",
    "        Drum Cartridge (R2): VALUE,\n",
    "        Drum Cartridge (R3): VALUE,\n",
    "        Drum Cartridge (R4): VALUE,\n",
    "        Waste Toner Container: VALUE,\n",
    "        Transfer Belt Cleaner: VALUE,\n",
    "        Second Bias Transfer Roll: VALUE,\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "\n",
    "Json is just unstructured data. Do I care about the dict matching each other. OR should I pull in csv, loop through (name, model & ip) -> into function <- {info}, then append to the json dict with printer['printer_name'] = {info}\n",
    "\n",
    "now you have a dictionary of dicts with different sets of values.\n",
    "\n",
    "### PSUEDO CODE:\n",
    "- Load in csv to Pandas\n",
    "- Add all additional columns\n",
    "- Set Index to Name\n",
    "- Use pandas to_dict function to make a dictionary of dictionaries with the key as printer name\n",
    "- Loop through dict calling right func for model -> set values through the return\n",
    "- Save dict to json\n",
    "\n",
    "### POST scrapper - Flask app\n",
    "- Cronjob to run .py script \n",
    "- Launch flask app\n",
    "- Load in json and present through index.html template\n",
    "- reload script every so often - have manual refresh\n",
    "\n",
    "\n",
    "multithreading\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "executor = ThreadPoolExecutor(12)\n",
    "\n",
    "futures = []\n",
    "\n",
    "for url in urls:\n",
    "    future = executor.submit(func, val)\n",
    "    futures.append(future)\n",
    "\n",
    "for future in futures:\n",
    "    print(future.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and web driver setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas, requests, datetime, urllib3, time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import asyncio\n",
    "from pyppeteer import launch \n",
    "\n",
    "# Just to load the webpage for one type of printer\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # it's more scalable to work in headless mode\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "# Ignore http warning and go to site\n",
    "urllib3.disable_warnings() \n",
    "\n",
    "# Pull in intial file for IPs to scrap\n",
    "df = pandas.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_url():\n",
    "    browser = await launch(headless=True)\n",
    "    page = await browser.newPage()\n",
    "    await page.goto(\"http://10.10.140.53/home/index.html#hashSupplies/hashHome\")\n",
    "    await page.screenshot({'path': 'example.png'})\n",
    "    await browser.close()\n",
    "    \n",
    "\n",
    "asyncio.get_running_loop().run_until_complete(get_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_altalink_levels(printer, Logging: bool=None) -> {}:\n",
    "    '''\n",
    "    Input:  printer: {}     -> Dictionary of base info and Data key meant to hold the results\n",
    "            Logging: bool   -> turn on in function console logging\n",
    "\n",
    "    Output: {} Dictionary    -> Returns found supply values in dictionary\n",
    "    '''\n",
    "\n",
    "    URL = f\"https://{ printer['ip'] }/stat/consumables.php\"\n",
    "    results = {}\n",
    "\n",
    "    #console log\n",
    "    if(Logging):\n",
    "        print (\"testing URL: \" + URL)\n",
    "\n",
    "    #Request page -> log and return if can't\n",
    "    try:\n",
    "        response = requests.get(URL, verify=False)\n",
    "        \n",
    "    except:\n",
    "        if(Logging):\n",
    "            print(f\"Can't reach { printer['ip'] }, Please check the printer\")\n",
    "        results[\"response\"] = \"None\"\n",
    "        printer['Data'].update(results)\n",
    "        return printer\n",
    "        \n",
    "    soup = bs(response.content, \"html.parser\")\n",
    "\n",
    "    for tab in soup.find_all('table', class_=\"tableDiv\"):\n",
    "        for tr in tab.find_all('tr'):\n",
    "            row = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "            d = []\n",
    "            if len(row) < 8:\n",
    "                continue\n",
    "            if(row[1]== 'Waste Toner Container'):\n",
    "                results[row[1]] = row[2]\n",
    "                continue\n",
    "            results[row[1]] = row[3]\n",
    "    \n",
    "    #Return the full dict\n",
    "    printer['Data'].update(results)\n",
    "    if(Logging):\n",
    "        print(printer)\n",
    "    \n",
    "    return printer\n",
    "\n",
    "#Parse the versalink webpage for the toner level\n",
    "def get_versalink_levels(printer, Logging: bool=None) -> {}:\n",
    "    '''\n",
    "    Input:  ip: str         -> IP to request page from for parsing\n",
    "            Logging: bool   -> turn on in function console logging\n",
    "\n",
    "    Output: {} Dictionary    -> Returns found supply values in dictionary\n",
    "    '''\n",
    "    \n",
    "    URL = f\"http://{ printer['ip'] }/home/index.html#hashSupplies/hashHome\"\n",
    "    results = {}\n",
    "\n",
    "    #console log\n",
    "    if(Logging):\n",
    "        print (\"testing URL: \" + URL)\n",
    "\n",
    "    #request page -> log and return if can't\n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        time.sleep(10)\n",
    "   \n",
    "    except:\n",
    "        if(Logging):\n",
    "            print(f\"Can't reach { printer['ip'] }, Please check the printer\")\n",
    "        results[\"response\"] = \"None\"\n",
    "        printer['Data'].update(results)\n",
    "        return printer\n",
    "\n",
    "    #Get source and parse for the specifc divs\n",
    "    soup = bs(driver.page_source, \"html.parser\")  \n",
    "    supplies = soup.select(\"html > body > div > div > div > main > div > article > div > section > div > div\")\n",
    "\n",
    "    for supply in supplies:\n",
    "        res = supply.get_text().rsplit(maxsplit=1)\n",
    "        res[0] = res[0].lstrip()\n",
    "        results[res[0]] = res[1]  #.strip(\"%\") #can be used to strip the % and we could cast to int\n",
    "\n",
    "    printer['Data'].update(results)\n",
    "    if(Logging):\n",
    "        print(printer)\n",
    "    return printer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing single execution of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of Altalink function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = {\n",
    "    \"Network Name\": \"T802-PS-C01\",\n",
    "    \"ip\": \"10.32.181.20\",\n",
    "    \"Model\": \"AltaLink C8135\",\n",
    "    \"Data\": {}\n",
    "}\n",
    "print(get_altalink_levels(tester, Logging=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of Versalink function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tester = {\n",
    "    \"Network Name\": \"G311-SA-C01\",\n",
    "    \"ip\": \"10.10.140.53\",\n",
    "    \"Model\": \"Versalink\",\n",
    "    \"Data\": {}\n",
    "}\n",
    "print(get_versalink_levels(tester, Logging=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altalink function exploration for parsing the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP = \"10.32.181.20\"\n",
    "URL = f\"https://{ IP }/stat/consumables.php\"\n",
    "results = {}\n",
    "\n",
    "#console log\n",
    "print (\"testing URL: \" + URL)\n",
    "\n",
    "#Request page -> log and return if can't\n",
    "try:\n",
    "    response = requests.get(URL, verify=False)\n",
    "except:\n",
    "    print(\"Can't reach IP, Please check the printer\")\n",
    "    \n",
    "soup = bs(response.content, \"html.parser\")\n",
    "\n",
    "for tab in soup.find_all('table', class_=\"tableDiv\"):\n",
    "    for tr in tab.find_all('tr'):\n",
    "        row = [td.text.strip() for td in tr.find_all(\"td\")]\n",
    "        d = []\n",
    "        if len(row) < 8:\n",
    "            continue\n",
    "        if(row[1]== 'Waste Toner Container'):\n",
    "            results[row[1]] = row[2]\n",
    "            continue\n",
    "        results[row[1]] = row[3]\n",
    "#Return the full dict\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versalink function exploration for pasring webpage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP = \"10.64.30.30\"\n",
    "URL = f\"http://{ IP }/home/index.html#hashSupplies/hashHome\"\n",
    "results = {}\n",
    "\n",
    "#console log\n",
    "print (\"testing URL: \" + URL)\n",
    "\n",
    "#request page -> log and return if can't\n",
    "try:\n",
    "    driver.get(URL)\n",
    "    time.sleep(5)\n",
    "except:\n",
    "    print(f\"Can't reach { IP }, Please check the printer\")\n",
    "\n",
    "#Get source and parse for the specifc divs\n",
    "soup = bs(driver.page_source, \"html.parser\")\n",
    "supplies = soup.select(\"html > body > div > div > div > main > div > article > div > section > div > div\")\n",
    "\n",
    "for supply in supplies:\n",
    "    #data.append(l.get_text().rsplit(maxsplit=1))\n",
    "    res = supply.get_text().rsplit(maxsplit=1)\n",
    "    res[0] = res[0].lstrip()\n",
    "    results[res[0]] = res[1]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe conversion for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df[['Network Name', 'ip' , 'Model']]\n",
    "\n",
    "ds_dict = ds.to_dict(orient=\"index\")\n",
    "\n",
    "#print(ds_dict)\n",
    "for d in ds_dict:\n",
    "    ds_dict[d][\"Data\"] = {}\n",
    "    #print(ds_dict[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old function\n",
    "\n",
    "Loop through dictionary and call specific function -> waits on results from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through IP list in Pandas. Set the Levels in new Array\n",
    "printer_level_list = []\n",
    "levels = []\n",
    "for d in ds_dict:\n",
    "    if \"AltaLink\" in ds_dict[d][\"Model\"]:\n",
    "        levels = get_altalink_levels(ds_dict[d])\n",
    "    if \"VersaLink\" in ds_dict[d][\"Model\"]:\n",
    "        levels = get_versalink_levels(ds_dict[d])\n",
    "    printer_level_list.append(levels)\n",
    "\n",
    "for printer in printer_level_list:\n",
    "    print(printer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Multi-Threadding function\n",
    "\n",
    "Sets up a pool of 34 threads to run at \"once\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make thread pool to run multiple function at once\n",
    "executor = ThreadPoolExecutor(10)\n",
    "futures = []\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "for d in ds_dict:\n",
    "    if \"AltaLink\" in ds_dict[d][\"Model\"]:\n",
    "        future = executor.submit(get_altalink_levels, ds_dict[d], True)\n",
    "        #futures.append(future)\n",
    "    if \"VersaLink\" in ds_dict[d][\"Model\"]:\n",
    "        future = executor.submit(get_versalink_levels, ds_dict[d], True)\n",
    "    futures.append(future)\n",
    "\n",
    "for future in futures:\n",
    "    result_dict[futures.index(future)] = future.result()\n",
    "    print(future.result())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in result_dict:\n",
    "    print(result_dict[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
